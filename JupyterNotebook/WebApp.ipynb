{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSONm77js1RW"
   },
   "source": [
    "## AI Road Safety Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBq9FeDU5eJE",
    "outputId": "7379351a-a274-48b1-ff11-dacc8320f66c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8odZzhyY14Xp"
   },
   "source": [
    "### 5. Deployment(배포)\n",
    "개발 제품 서비스(Gradio, Flask, Streamit 등 활용) 플랫폼에서 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtHYKnwm14Xp"
   },
   "source": [
    "#### 5.1 배포를 위해 필요한 라이브러리 불러오기\n",
    "개발된 AI Project을 어떤 형태로 서비스 할 것인지를 결정하고 필요한 라이브러리를 불러온다. 여기서는 Gradio를 활용한 것으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7vxI_2O2BP2",
    "outputId": "85a3ccd2-5ba9-45ad-c389-954b1099012d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openvino in c:\\users\\creamel\\anaconda3\\lib\\site-packages (2024.5.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.16.6 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from openvino) (1.26.4)\n",
      "Requirement already satisfied: openvino-telemetry>=2023.2.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from openvino) (2024.5.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from openvino) (24.1)\n",
      "Requirement already satisfied: gradio in c:\\users\\creamel\\anaconda3\\lib\\site-packages (5.8.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.5.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.26.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.0.19)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.8.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio-client==1.5.1->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Requirement already satisfied: roboflow in c:\\users\\creamel\\anaconda3\\lib\\site-packages (1.1.49)\n",
      "Requirement already satisfied: certifi in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (0.21.0)\n",
      "Requirement already satisfied: requests in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (4.66.5)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib->roboflow) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\creamel\\anaconda3\\lib\\site-packages (8.3.40)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\creamel\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openvino\n",
    "!pip install gradio\n",
    "!pip install roboflow\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeZZOnBW14Xq",
    "outputId": "d8db985d-1e1f-4ee0-9ba3-8e3a3be4409b"
   },
   "outputs": [],
   "source": [
    "#필요 라이브러리 불러오기\n",
    "import ultralytics\n",
    "import openvino as ov\n",
    "import gradio as gr\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2DV_bfM16PJ",
    "outputId": "9e38031c-9ad6-4600-cf0a-3a85b37d04ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Fall-Detection-4 to yolov8:: 100%|██████████| 527722/527722 [00:36<00:00, 14647.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Fall-Detection-4 in yolov8:: 100%|██████████| 21586/21586 [00:03<00:00, 5752.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"gdjOG6iEgCYsDr8CCQ2K\")\n",
    "project = rf.workspace(\"roboflow-universe-projects\").project(\"fall-detection-ca3o8\")\n",
    "dataset = project.version(4).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1fV0z2S2XZ4",
    "outputId": "7f503fe5-3f51-4473-f649-dcd36e0ea4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% 0.00/6.25M [00:00<?, ?B/s]\r",
      "100% 6.25M/6.25M [00:00<00:00, 134MB/s]\n",
      "Ultralytics 8.3.42 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/Fall-Detection-4/data.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "100% 755k/755k [00:00<00:00, 89.6MB/s]\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "100% 5.35M/5.35M [00:00<00:00, 76.5MB/s]\n",
      "WARNING ⚠️ NMS time limit 2.400s exceeded\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Fall-Detection-4/train/labels... 9438 images, 0 backgrounds, 0 corrupt: 100% 9438/9438 [00:19<00:00, 488.57it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Fall-Detection-4/train/labels.cache\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Fall-Detection-4/valid/labels... 899 images, 0 backgrounds, 0 corrupt: 100% 899/899 [00:01<00:00, 461.59it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Fall-Detection-4/valid/labels.cache\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      2.27G      1.408      2.032      1.737         34        640: 100% 590/590 [05:58<00:00,  1.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:25<00:00,  1.12it/s]\n",
      "                   all        899        899      0.494      0.444      0.444       0.18\n",
      "\n",
      "1 epochs completed in 0.111 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.42 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:18<00:00,  1.61it/s]\n",
      "                   all        899        899      0.496       0.44      0.445      0.181\n",
      "Speed: 0.3ms preprocess, 2.5ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo train model=yolov8n.pt data={dataset.location}/data.yaml epochs=1 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnveuXdx14Xq"
   },
   "source": [
    "#### 5.2 개발한 모델 불러오기\n",
    "모델 평가를 통해 선정한 최적 모델을 불러온다. 모델은 models 폴더에 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pE7Wx66xZdW7",
    "outputId": "95ead5c4-e56b-4a21-d0d7-c3f2b6dfbc66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.40  Python-3.12.7 torch-2.5.1+cpu CPU (Intel Core(TM) i7-9700 3.00GHz)\n",
      "Model summary (fused): 218 layers, 25,840,339 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (49.6 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.5.0-17288-7975fa5da0c-refs/pull/3856/head...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  3.6s, saved as 'best_openvino_model\\' (99.0 MB)\n",
      "\n",
      "Export complete (4.5s)\n",
      "Results saved to \u001b[1mC:\\Users\\Creamel\\Test\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=best_openvino_model imgsz=640 data=./People-Detection-8/data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'best_openvino_model'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a YOLOv8n PyTorch model\n",
    "model = YOLO('./best.pt')\n",
    "\n",
    "# Export the model\n",
    "model.export(format='openvino')  # creates 'yolov8n_openvino_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mE33Il2h14Xr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer shape:  [1,3,640,640]\n",
      "Output layer shape: [1,5,8400]\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "core = ov.Core()\n",
    "\n",
    "model = core.read_model(model=\"./best_openvino_model/best.xml\")\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "print(\"Input layer shape: \", input_layer.shape)\n",
    "print(\"Output layer shape:\", output_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cMlxbUZR14Xr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person'}\n"
     ]
    }
   ],
   "source": [
    "# 레이블 불러오기\n",
    "with open('./best_openvino_model/metadata.yaml') as info:\n",
    "      info_dict = yaml.load(info, Loader=yaml.Loader)\n",
    "\n",
    "labels = info_dict['names']\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kS3iKBs14Xs"
   },
   "source": [
    "#### 5.3 새로운 입력 데이터 Shape 맞추기\n",
    "새로 입력될 데이터의 Shape를 맞추어 주는 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BgzNchgx14Xs"
   },
   "outputs": [],
   "source": [
    "# 새로운 데이터 입력 shape 맞추는 함수\n",
    "def prepare_data(image):\n",
    "    input_w, input_h = 640, 640\n",
    "    input_image = cv2.resize(image, (input_w,input_h))\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "    input_image = input_image/255\n",
    "\n",
    "    input_image = input_image.transpose(2, 0, 1)\n",
    "    input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "    return input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFUj6VSO14Xs"
   },
   "source": [
    "#### 5.4 추론 결과 저장하기\n",
    "새로 입력된 데이터의 추론 한 결과 값을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rmSXKXyU14Xs"
   },
   "outputs": [],
   "source": [
    "# 새로운 이미지 데이터 추론 함수\n",
    "def predict_image(image, conf_threshold):\n",
    "    input_image = prepare_data(image)\n",
    "    output = compiled_model([input_image])[output_layer]\n",
    "    boxes, scores, label_key = evaluate(output, conf_threshold)\n",
    "    if len(boxes):\n",
    "        nms_output = non_max_suppression(boxes, scores, conf_threshold)\n",
    "        visualize(nms_output, boxes, image, label_key, scores, colors_dict)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EQ__ykg614Xs"
   },
   "outputs": [],
   "source": [
    "# 새로운 영상 데이터 추론 함수\n",
    "def predict_video(vid_input, conf_threshold):\n",
    "    colors_dict = create_colors(labels)\n",
    "    video_capture = cv2.VideoCapture(vid_input)\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'vp80')\n",
    "    vid_name= 'output.webm'\n",
    "    width_out  = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height_out = int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    out = cv2.VideoWriter(vid_name, fourcc, 20.0, (width_out, height_out))\n",
    "    while(True):\n",
    "        ret, frame = video_capture.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        input_image = prepare_data(frame)\n",
    "        output = compiled_model([input_image])[output_layer]\n",
    "        boxes, scores, label_names = evaluate(output, conf_threshold)\n",
    "\n",
    "        if len(boxes):\n",
    "            nms_output = non_max_suppression(boxes, scores, .5)\n",
    "            visualize(nms_output, boxes, frame, label_names, scores, colors_dict)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    file_path = \"output.webm\"\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pSQDEQM14Xs"
   },
   "source": [
    "#### 5.5 추론 결과 후처리: Post processing with the result of inference\n",
    "- confidence 이상의 바운딩 박스와 레이블 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "A4rZjst414Xt"
   },
   "outputs": [],
   "source": [
    "# confidence 이상의 바운딩 박스 찾는 함수\n",
    "def evaluate(output, conf):\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    label_key = []\n",
    "    label_index = 0\n",
    "\n",
    "    for class_ in output[0][4:]:\n",
    "        for index in range (len(class_)):\n",
    "            confidence = class_[index]\n",
    "\n",
    "            if  confidence > conf:\n",
    "                xcen = output[0][0][index]\n",
    "                ycen = output[0][1][index]\n",
    "                w = output[0][2][index]\n",
    "                h = output[0][3][index]\n",
    "\n",
    "                xmin = int(xcen - (w/2))\n",
    "                xmax = int(xcen + (w/2))\n",
    "                ymin = int(ycen - (h/2))\n",
    "                ymax = int(ycen + (h/2))\n",
    "\n",
    "                box = (xmin, ymin, xmax, ymax)\n",
    "                boxes.append(box)\n",
    "                scores.append(confidence)\n",
    "\n",
    "                label_key.append(label_index)\n",
    "\n",
    "        label_index += 1\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    return boxes, scores, label_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtACppbB14Xt"
   },
   "source": [
    "- 박스 하나 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VP7lvM0X14Xt"
   },
   "outputs": [],
   "source": [
    "# 가장 큰\n",
    "def non_max_suppression(boxes, scores, iou_threshold):\n",
    "    assert boxes.shape[0] == scores.shape[0]\n",
    "    ys1 = boxes[:, 0]\n",
    "    xs1 = boxes[:, 1]\n",
    "    ys2 = boxes[:, 2]\n",
    "    xs2 = boxes[:, 3]\n",
    "    areas = (ys2 - ys1) * (xs2 - xs1)\n",
    "\n",
    "    scores_indexes = scores.argsort().tolist()\n",
    "    boxes_keep_index = []\n",
    "\n",
    "    while len(scores_indexes):\n",
    "        index = scores_indexes.pop()\n",
    "        boxes_keep_index.append(index)\n",
    "        if not len(scores_indexes):\n",
    "            break\n",
    "        ious = compute_iou(boxes[index], boxes[scores_indexes], areas[index], areas[scores_indexes])\n",
    "        filtered_indexes = set((ious > iou_threshold).nonzero()[0])\n",
    "        scores_indexes = [\n",
    "            v for (i, v) in enumerate(scores_indexes)\n",
    "            if i not in filtered_indexes\n",
    "        ]\n",
    "    return np.array(boxes_keep_index)\n",
    "\n",
    "def compute_iou(box, boxes, box_area, boxes_area):\n",
    "    assert boxes.shape[0] == boxes_area.shape[0]\n",
    "    ys1 = np.maximum(box[0], boxes[:, 0])\n",
    "    xs1 = np.maximum(box[1], boxes[:, 1])\n",
    "    ys2 = np.minimum(box[2], boxes[:, 2])\n",
    "    xs2 = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    intersections = np.maximum(ys2 - ys1, 0) * np.maximum(xs2 - xs1, 0)\n",
    "    unions = box_area + boxes_area - intersections\n",
    "    ious = intersections / unions\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8ehFRlo14Xt"
   },
   "source": [
    "- 레이블별 박스 컬러 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JKOsQTyU14Xt"
   },
   "outputs": [],
   "source": [
    "# 박스 컬러 함수\n",
    "def create_colors(labels):\n",
    "    colors_dict = {}\n",
    "    for i in range(len(labels)):\n",
    "        random_color = list(np.random.randint(0,255, size =3))\n",
    "        random_color = ( int (random_color [ 0 ]), int (random_color [ 1 ]), int (random_color [ 2 ]))\n",
    "        colors_dict[i] = random_color\n",
    "    return colors_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihKhfE9e14Xt"
   },
   "source": [
    "- 박스 그리기 및 레이블 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gdNVX3lY14Xu"
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import json\n",
    "# 시각화 함수\n",
    "countHuman = 0\n",
    "robotcount = [0,0,0]\n",
    "def visualize(nms_output, boxes, orig_image, label_key,scores, colors_dict ):\n",
    "    countHuman = len(nms_output)\n",
    "    orig_h, orig_w, c = orig_image.shape\n",
    "    for i in nms_output:\n",
    "        xmin, ymin, xmax, ymax = boxes[i]\n",
    "        xmin = int(xmin*orig_w/640)\n",
    "        ymin = int(ymin*orig_h/640)\n",
    "        xmax = int(xmax*orig_w/640)\n",
    "        ymax = int(ymax*orig_h/640)\n",
    "        color = colors_dict[label_key[i]]\n",
    "        cv2.rectangle(orig_image, (xmin,ymin), (xmax,ymax), color, 4)\n",
    "        text = str(int(np.rint(scores[i]*100))) + \"% \" + str(labels[label_key[i]])\n",
    "        cv2.putText(orig_image, text, (xmin+2,ymin-5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   1, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    cv2.putText(orig_image, f\"Human Count : {countHuman}\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "    if(countHuman > 5):\n",
    "        url = 'http://127.0.0.1:8000/robots'\n",
    "        r = requests.get(url)\n",
    "        j = r.json()\n",
    "        cv2.putText(orig_image, json.dumps(j), (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2, cv2.LINE_AA)\n",
    "        if(j[\"robot1\"] == 0):\n",
    "            #Post Robot1 to \n",
    "            url = f\"http://127.0.0.1:8000/robot/robot1\"\n",
    "            data = {\n",
    "                'location' : 2,\n",
    "            }\n",
    "            api_headers = {}\n",
    "            res = requests.put(url, data= json.dumps(data), headers=api_headers)\n",
    "        elif(j[\"robot2\"] == 0):\n",
    "            #Post Robot2 to \n",
    "            url = f\"http://127.0.0.1:8000/robot/robot2\"\n",
    "            data = {\n",
    "                'location' : 2,\n",
    "            }\n",
    "            api_headers = {}\n",
    "            res = requests.put(url, data= json.dumps(data), headers=api_headers)\n",
    "        \n",
    "        elif(j[\"robot3\"] == 0):\n",
    "            #Post Robot3 to \n",
    "            url = f\"http://127.0.0.1:8000/robot/robot3\"\n",
    "            data = {\n",
    "                'location' : 2,\n",
    "            }\n",
    "            api_headers = {}\n",
    "            res = requests.put(url, data= json.dumps(data), headers=api_headers)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uK9SIwWC14Xu"
   },
   "source": [
    "#### 5.6 Web Deployment with Gradio\n",
    "새로 입력될 데이터의 Shape를 맞추어 주는 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "fGzv-i_v14Xu"
   },
   "outputs": [],
   "source": [
    "image_iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Upload Image\"),\n",
    "        gr.Slider(minimum=0, maximum=1, value=0.25, label=\"Confidence threshold\"),\n",
    "    ],\n",
    "    outputs=gr.Image(label=\"Result\"),\n",
    ")\n",
    "\n",
    "video_iface = gr.Interface(\n",
    "    fn=predict_video,\n",
    "    inputs=[\n",
    "        gr.Video(label = \"Upload Video\"),\n",
    "        gr.Slider(minimum=0, maximum=1, value=0.25, label=\"Confidence threshold\"),\n",
    "    ],\n",
    "    outputs=gr.Video(label=\"Result\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "demo = gr.TabbedInterface([image_iface, video_iface], [\"Image\", \"Video\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "8lLeXkvF14Xu",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors_dict = create_colors(labels)\n",
    "if __name__ == '__main__':\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvS-aNRW14Xu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
